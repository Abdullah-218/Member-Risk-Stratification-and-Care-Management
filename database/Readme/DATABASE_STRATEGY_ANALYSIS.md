# Database Strategy Analysis & Design Recommendations
**Date**: January 29, 2026  
**Status**: Pre-Implementation Analysis  
**System**: Healthcare Risk ML Platform with PostgreSQL  

---

## ğŸ¯ Your 5 Core Requirements - Strategic Analysis

### Requirement 1: Organization Database (3K Baseline)
**"X_test 3k rows dataset should be stored as organization database where all patients data are available"**

#### Current State Analysis:
```
X_test.csv structure:
â”œâ”€ 3,000 rows Ã— 27 columns
â”œâ”€ ALL 27 features are PRE-ENGINEERED (not raw data)
â”œâ”€ Contains both demographics AND derived metrics
â””â”€ Ready to load directly into database
```

#### Strategic Approach:
**Do NOT treat X_test as "raw input"** - it's your BASELINE REFERENCE dataset

```
Design Principle:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  X_test = Organization Baseline Repository        â”‚
â”‚  â”œâ”€ All 3K patients: permanent record             â”‚
â”‚  â”œâ”€ 27 features: template for all features        â”‚
â”‚  â”œâ”€ Source: Historical claims data (2008)         â”‚
â”‚  â””â”€ Update: Quarterly refresh with new cohort     â”‚
â”‚                                                    â”‚
â”‚  New Patients = Real-time Intake                   â”‚
â”‚  â”œâ”€ Individual patients: 1 at a time              â”‚
â”‚  â”œâ”€ Raw data: ~10-15 fields (not 27)              â”‚
â”‚  â”œâ”€ Source: Frontend forms + system inputs        â”‚
â”‚  â””â”€ Update: As they enter the system              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Database Storage Strategy:

**Table 1: organizations**
- Contains 1 record: YOUR ORGANIZATION
- Stores: org_name, org_code, creation_date
- Purpose: Multi-tenant ready (support scaling to multiple orgs later)

**Table 2: patients**
- 3,000 baseline + N new patients (grows over time)
- Core fields: patient_id (PK), external_id, age, gender, race, department_id
- Metadata: data_source ('X_TEST' vs 'NEW_PATIENT'), created_at, updated_at
- Financial: annual_cost, cost_percentile (baseline from X_test)
- Purpose: Master patient registry - single source of truth

**Table 3: patient_features**
- 1:1 with patients table
- ALL 27 features stored as COLUMNS (not JSON, not BLOB)
- Why columns: Queryable, indexable, type-safe
- Fields: is_elderly, has_diabetes, total_admissions, frailty_score, etc.
- Purpose: Feature repository - enables feature-based queries and updates

#### Key Design Insight:
```
âœ… GOOD: Store all 27 features as database columns
âŒ AVOID: Store as JSON blob (you lose queryability)
âŒ AVOID: Calculate features on-the-fly (slow for 3K queries)

Result: Fast queries like "SELECT * FROM patient_features WHERE complexity_index > 0.8 AND has_diabetes = 1"
```

#### Why This Approach:
- 3,000 patients occupy small disk space (~150MB)
- All 27 features indexed for fast filtering
- New patients follow same schema (same 27 columns)
- Enables comparison: baseline vs new cohort
- Supports analytics: feature distributions, correlations

---

### Requirement 2: Predicted Organization Data (Window-Wise & Tier-Wise)
**"Predicted organization data that is window wise / tier wise data and no. of patients in each data are stored accordingly"**

#### Current State Understanding:
```
You need to show:
1. For each time window (30, 60, 90 days)
2. Risk distribution across 5 tiers
3. Patient COUNT in each tier
4. PERCENTAGE of cohort in each tier
```

#### Example Output You Need:
```
WINDOW: 30_DAY
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Tier   â”‚ Description  â”‚ Count  â”‚ Percentage â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   1    â”‚ Normal       â”‚ 1,950  â”‚   65.0%    â”‚
â”‚   2    â”‚ Low Risk     â”‚  600   â”‚   20.0%    â”‚
â”‚   3    â”‚ Moderate     â”‚  300   â”‚   10.0%    â”‚
â”‚   4    â”‚ High Risk    â”‚  120   â”‚    4.0%    â”‚
â”‚   5    â”‚ Critical     â”‚   30   â”‚    1.0%    â”‚
â”‚  TOTAL â”‚              â”‚ 3,000  â”‚  100.0%    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

WINDOW: 60_DAY (similar)
WINDOW: 90_DAY (similar)
```

#### Strategic Storage Design:

**Table 4: predictions**
- One record per patient per window
- Structure: patient_id, prediction_window ('30_day'/'60_day'/'90_day'), risk_score (0.0-1.0), risk_tier (1-5)
- Size: 3,000 patients Ã— 3 windows = 9,000 records
- Metadata: prediction_timestamp, model_version, is_active
- Purpose: Atomic prediction storage - audit trail of all predictions

**Table 5: prediction_aggregations (Materialized View)**
- Pre-calculated tier distribution per window
- Structure: prediction_window, risk_tier, patient_count, percentage
- Size: 3 windows Ã— 5 tiers = 15 records (VERY small)
- Update frequency: After each prediction batch
- Purpose: Fast frontend display (no calculation needed)

#### Storage Strategy:

```
Data Flow for Requirement 2:

Step 1: Run predictions
  Load 27 features â†’ ML Models (3 windows) â†’ Get risk_scores (0-1)

Step 2: Convert scores to tiers
  0.0-0.2 â†’ Tier 1 (Normal)
  0.2-0.4 â†’ Tier 2 (Low)
  0.4-0.6 â†’ Tier 3 (Moderate)
  0.6-0.8 â†’ Tier 4 (High)
  0.8-1.0 â†’ Tier 5 (Critical)

Step 3: Store predictions
  INSERT INTO predictions (patient_id, prediction_window, risk_score, risk_tier)
  â†’ Creates 9,000 records

Step 4: Aggregate for display
  CREATE MATERIALIZED VIEW org_tier_summary AS
  SELECT prediction_window, risk_tier, COUNT(*) as patient_count
  FROM predictions WHERE is_active = TRUE
  GROUP BY prediction_window, risk_tier

Step 5: Frontend gets summary
  SELECT * FROM org_tier_summary
  â†’ Returns 15 pre-calculated rows (instant response)
```

#### Why This Design:
- âœ… Predictions stored atomically (can audit any individual prediction)
- âœ… Aggregation pre-calculated (frontend is FAST)
- âœ… Window-wise breakdown (can compare windows)
- âœ… Tier counts known (can allocate interventions per tier)
- âœ… Scalable (adding 1 patient = 3 new predictions, not recompute all 9K)

---

### Requirement 3: ROI Calculations & Investments
**"Calculated ROI investments, intervention cost, net benefits, overall ROI, positive ROI patients with their details"**

#### What You Need to Calculate:

```
For EACH patient's EACH window prediction:

Input Variables:
â”œâ”€ annual_cost (from patient table)
â”œâ”€ prediction_window ('30_day', '60_day', '90_day')
â”œâ”€ risk_tier (1-5, from prediction)
â”œâ”€ actual_readmission (from ground truth, if available)
â””â”€ model_success_rate (by window and tier)

Calculated Metrics:
â”œâ”€ window_cost = annual_cost / 365 * days_in_window
â”œâ”€ addressable_cost = window_cost Ã— 0.60 (60% preventable)
â”œâ”€ intervention_cost = cost_per_tier[tier] (varies by risk level)
â”œâ”€ expected_savings = addressable_cost Ã— success_rate[tier][window]
â”œâ”€ net_benefit = expected_savings - intervention_cost
â”œâ”€ roi_percent = (net_benefit / intervention_cost) Ã— 100
â”œâ”€ roi_category = EXCELLENT|STRONG|POSITIVE|NO_ROI
â””â”€ positive_roi_flag = roi_percent > 0
```

#### Strategic Storage Design:

**Table 6: financial_projections**
- One record per prediction (same granularity as predictions)
- Links: patient_id â†’ prediction_id â†’ financial details
- Structure:
  ```
  â”œâ”€ Costs
  â”‚  â”œâ”€ annual_cost (reference)
  â”‚  â”œâ”€ window_cost (calculated)
  â”‚  â”œâ”€ addressable_cost (calculated)
  â”‚  â””â”€ intervention_cost (by tier)
  â”‚
  â”œâ”€ Savings
  â”‚  â”œâ”€ expected_savings (calculated)
  â”‚  â””â”€ success_rate (by tier, by window)
  â”‚
  â”œâ”€ ROI
  â”‚  â”œâ”€ net_benefit (calculated)
  â”‚  â”œâ”€ roi_percent (0-100%, capped)
  â”‚  â””â”€ roi_category (EXCELLENT/STRONG/POSITIVE/NO_ROI)
  â”‚
  â””â”€ Audit
     â”œâ”€ calculation_timestamp
     â””â”€ calculation_notes
  ```
- Size: 3,000 Ã— 3 = 9,000 records

**Table 7: roi_aggregations (Materialized View)**
- Summary statistics for organization
- Structure:
  ```
  â”œâ”€ prediction_window
  â”œâ”€ total_patients_analyzed
  â”œâ”€ avg_roi_percent
  â”œâ”€ positive_roi_count
  â”œâ”€ excellent_roi_count
  â”œâ”€ total_intervention_cost
  â”œâ”€ total_expected_savings
  â””â”€ total_net_benefit
  ```
- Size: 3 records (one per window)
- Purpose: Show "Is the intervention program worth it?" at org level

**Table 8: positive_roi_patients (Materialized View)**
- List of patients where roi_percent > 0
- Structure: patient_id, patient_name, annual_cost, tier, window, roi_percent, roi_category
- Size: ~50-60% of predictions (1,500-1,800 records)
- Purpose: "Which patients should we target?" for intervention program

#### Key Design Insights:

```
âŒ DON'T: Store calculations in code, recalculate on every query
  Reason: 10 queries Ã— 9K records = 90K calculations (slow)

âœ… DO: Calculate once â†’ Store â†’ Aggregate in views
  Reason: 10 queries on pre-calculated data (instant)

ğŸ“Š ROI Storage Strategy:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ATOMIC: financial_projections (9,000 records)      â”‚
â”‚  â”œâ”€ One row per patient per window                  â”‚
â”‚  â”œâ”€ All calculations stored explicitly              â”‚
â”‚  â”œâ”€ Enables audit trail                             â”‚
â”‚  â””â”€ Supports "recalculate if costs change"          â”‚
â”‚                                                      â”‚
â”‚  AGGREGATE: roi_aggregations (3 materialized views) â”‚
â”‚  â”œâ”€ View 1: Organization-wide ROI by window         â”‚
â”‚  â”œâ”€ View 2: Positive ROI patients with details      â”‚
â”‚  â””â”€ Refreshed after each prediction batch           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### ROI Calculation Example:

```
Patient Example:
â”œâ”€ annual_cost: $45,000
â”œâ”€ prediction_window: 30_day (30 days)
â”œâ”€ risk_tier: 4 (High Risk)
â”œâ”€ days_in_window: 30

Calculations:
â”œâ”€ window_cost = 45,000 / 365 Ã— 30 = $3,699
â”œâ”€ addressable_cost = $3,699 Ã— 0.60 = $2,219 (preventable)
â”œâ”€ intervention_cost = $500 (tier 4 program cost)
â”œâ”€ success_rate[tier_4][30_day] = 45% (historical)
â”œâ”€ expected_savings = $2,219 Ã— 0.45 = $999
â”œâ”€ net_benefit = $999 - $500 = $499
â”œâ”€ roi_percent = ($499 / $500) Ã— 100 = 99.8% âœ… EXCELLENT
â””â”€ positive_roi: YES âœ…

Storage:
INSERT INTO financial_projections (
    patient_id, prediction_id, prediction_window, risk_tier,
    annual_cost, window_cost, addressable_cost,
    intervention_cost, expected_savings, net_benefit, roi_percent, roi_category
) VALUES (
    5001, 15003, '30_day', 4,
    45000, 3699, 2219,
    500, 999, 499, 99.8, 'EXCELLENT'
)
```

---

### Requirement 4: Department Database (High-Risk & Critical by Condition)
**"Department database where we store high risk and critical patients based on several departments (neurology, etc.) in healthcare with distributed patient count"**

#### Strategic Challenge Identified:
```
Your Current Situation:
â”œâ”€ X_test has 3,000 patients
â”œâ”€ NO "department_id" field in data
â”œâ”€ NO "patient_department" mapping
â”œâ”€ Patient IDs are VERY LARGE numbers (DESYNPUF_ID format)
â”œâ”€ 10 departments needed (neurology, cardiology, etc.)
â””â”€ High-risk + Critical only? Or all patients distributed?

Question: How to assign patients to departments?
```

#### Department Assignment Logic - 3 Options:

**OPTION A: Condition-Based Assignment (RECOMMENDED for Clinical Meaning)**

Logic: Route patient to department based on PRIMARY CHRONIC CONDITION

```
CLINICAL DEPARTMENT ROUTING:

1. CARDIOLOGY
   â”œâ”€ Condition triggers: has_chf OR has_ischemic_heart
   â”œâ”€ Expected patients: ~800-1000 (25-33%)
   â””â”€ Rationale: CHF + heart disease need specialized cardio care

2. NEPHROLOGY
   â”œâ”€ Condition triggers: has_ckd OR has_esrd
   â”œâ”€ Expected patients: ~600-800 (20-27%)
   â””â”€ Rationale: CKD/ESRD requires dialysis + specialized care

3. ENDOCRINOLOGY
   â”œâ”€ Condition triggers: has_diabetes (AND NOT Cardiology/Nephrology)
   â”œâ”€ Expected patients: ~400-600 (13-20%)
   â””â”€ Rationale: Diabetes management + complication prevention

4. PULMONOLOGY/RESPIRATORY
   â”œâ”€ Condition triggers: has_copd (AND NOT above)
   â”œâ”€ Expected patients: ~200-300 (7-10%)
   â””â”€ Rationale: COPD + oxygen therapy

5. NEUROLOGY
   â”œâ”€ Condition triggers: has_stroke OR has_alzheimers
   â”œâ”€ Expected patients: ~150-250 (5-8%)
   â””â”€ Rationale: Neurological conditions + cognitive decline

6. ONCOLOGY
   â”œâ”€ Condition triggers: has_cancer (AND NOT above)
   â”œâ”€ Expected patients: ~100-150 (3-5%)
   â””â”€ Rationale: Cancer management + chemotherapy

7. PSYCHIATRY
   â”œâ”€ Condition triggers: has_depression (AND NOT above)
   â”œâ”€ Expected patients: ~100-150 (3-5%)
   â””â”€ Rationale: Mental health + medication management

8. RHEUMATOLOGY
   â”œâ”€ Condition triggers: has_ra_oa (AND NOT above)
   â”œâ”€ Expected patients: ~50-100 (2-3%)
   â””â”€ Rationale: Arthritis + joint care

9. GERIATRICS
   â”œâ”€ Condition triggers: is_elderly (age >75) AND high_complexity
   â”œâ”€ Expected patients: ~200-300 (7-10%)
   â””â”€ Rationale: Elderly + multi-morbidity management

10. GENERAL MEDICINE
    â”œâ”€ Condition triggers: No primary condition OR multiple equally severe
    â”œâ”€ Expected patients: ~300-500 (10-17%)
    â””â”€ Rationale: Preventive care + overall health maintenance

TOTAL: 3,000 patients distributed across 10 departments
```

**Assignment Algorithm (Pseudo-code):**
```
FOR each patient:
    IF has_chf OR has_ischemic_heart THEN
        dept_id = CARDIOLOGY
    ELSE IF has_ckd OR has_esrd THEN
        dept_id = NEPHROLOGY
    ELSE IF has_diabetes THEN
        dept_id = ENDOCRINOLOGY
    ELSE IF has_copd THEN
        dept_id = PULMONOLOGY
    ELSE IF has_stroke OR has_alzheimers THEN
        dept_id = NEUROLOGY
    ELSE IF has_cancer THEN
        dept_id = ONCOLOGY
    ELSE IF has_depression THEN
        dept_id = PSYCHIATRY
    ELSE IF has_ra_oa THEN
        dept_id = RHEUMATOLOGY
    ELSE IF is_elderly AND complexity_index > 5 THEN
        dept_id = GERIATRICS
    ELSE
        dept_id = GENERAL_MEDICINE
    
    UPDATE patients SET department_id = dept_id WHERE patient_id = X
```

**Why This Approach:**
- âœ… Clinically meaningful (real departments in hospitals)
- âœ… Data-driven (uses actual conditions from X_test)
- âœ… Scalable (can add specialties)
- âœ… Easy to audit (can trace why patient in dept)
- âœ… Enables department-specific interventions

---

**OPTION B: Risk-Tier Based Distribution (FASTEST)**

```
If you need quick department assignment:

1. CRITICAL_CARE       â†’ Tier 5 patients
2. ICU_MONITORING      â†’ Tier 4 patients
3. HIGH_RISK_OUTPT     â†’ Tier 3 patients
4. STANDARD_CARE       â†’ Tier 2 patients
5. WELLNESS_PROGRAM    â†’ Tier 1 patients

Pros: Fast, risk-aligned
Cons: Not clinically meaningful, doesn't match real departments
```

---

**OPTION C: Hybrid (BALANCED)**

```
Assign to clinical department (Option A)
BUT track risk_tier alongside department

Result:
â”œâ”€ CARDIOLOGY
â”‚  â”œâ”€ Tier 1: 300 patients (normal risk cardio)
â”‚  â”œâ”€ Tier 2: 250 patients (low risk cardio)
â”‚  â”œâ”€ Tier 3: 150 patients (moderate risk cardio)
â”‚  â”œâ”€ Tier 4: 80 patients (high risk cardio)
â”‚  â””â”€ Tier 5: 20 patients (critical cardio)
â”‚
â”œâ”€ NEPHROLOGY
â”‚  â”œâ”€ Tier 1: 200 patients
â”‚  â”œâ”€ Tier 2: 200 patients
â”‚  ... etc
```

This gives you BOTH clinical meaning AND risk stratification.

---

#### Database Design for Departments:

**Table 9: departments**
```
â”œâ”€ department_id (PK): 1-10
â”œâ”€ department_code: 'CARDIOLOGY', 'NEPHROLOGY', etc.
â”œâ”€ department_name: Full name
â”œâ”€ specialty_type: 'CARDIAC', 'RENAL', etc.
â”œâ”€ description: Clinical focus
â””â”€ created_at: When added
```

**Table 10: dept_risk_distribution (Materialized View)**
```
Example output:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Department                  â”‚ Tier â”‚ Count â”‚ Percentage â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ CARDIOLOGY                  â”‚  1   â”‚ 300   â”‚   10%      â”‚
â”‚ CARDIOLOGY                  â”‚  2   â”‚ 250   â”‚   8%       â”‚
â”‚ CARDIOLOGY                  â”‚  3   â”‚ 150   â”‚   5%       â”‚
â”‚ CARDIOLOGY                  â”‚  4   â”‚  80   â”‚   3%       â”‚
â”‚ CARDIOLOGY                  â”‚  5   â”‚  20   â”‚   1%       â”‚
â”‚ NEPHROLOGY                  â”‚  1   â”‚ 200   â”‚   7%       â”‚
â”‚ ... (50 rows total)                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Query:
SELECT dept.department_name, pred.risk_tier, COUNT(*) as patient_count
FROM patients p
JOIN departments dept ON p.department_id = dept.department_id
JOIN predictions pred ON p.patient_id = pred.patient_id
WHERE pred.prediction_window = '30_day'
GROUP BY dept.department_id, pred.risk_tier
```

**Table 11: high_risk_by_department (Materialized View)**
```
Shows only Tier 4 + 5 patients per department:

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Department                  â”‚ Tier â”‚ Count    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ CARDIOLOGY                  â”‚  4   â”‚   80     â”‚
â”‚ CARDIOLOGY                  â”‚  5   â”‚   20     â”‚
â”‚ NEPHROLOGY                  â”‚  4   â”‚   60     â”‚
â”‚ NEPHROLOGY                  â”‚  5   â”‚   10     â”‚
â”‚ ... (20 rows: 10 depts Ã— 2 tiers)              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Total high/critical: ~200-250 patients (~7-8% of 3K)

Calculation:
SELECT dept.department_name, pred.risk_tier, COUNT(*) as patient_count
FROM patients p
JOIN departments dept ON p.department_id = dept.department_id
JOIN predictions pred ON p.patient_id = pred.patient_id
WHERE pred.risk_tier IN (4, 5)
  AND pred.prediction_window = '30_day'
GROUP BY dept.department_id, pred.risk_tier
```

---

### Requirement 5: New Patient Integration & Database Updates
**"When individual patient predicts their info also stores in 3k row database then again it updates by ML model"**

#### Current State Understanding:
```
New Patient Flow:
â”œâ”€ Patient enters raw data (10-15 fields)
â”œâ”€ System engineers to 27 features
â”œâ”€ ML model predicts for 3 windows
â”œâ”€ Store prediction + ROI in database
â”œâ”€ UPDATE organization statistics
â””â”€ Display results to user
```

#### Strategic Design:

**Table 12: new_patient_raw_input** (Optional - for audit trail)
```
Stores raw input exactly as received:
â”œâ”€ raw_input_id (PK)
â”œâ”€ patient_id (FK â†’ patients)
â”œâ”€ input_json (JSON of original raw data)
â”œâ”€ received_timestamp
â”œâ”€ source_system ('FRONTEND_FORM', 'API', 'IMPORTED')
â””â”€ processed_at

Why store raw?
âœ… Audit trail (what was input originally?)
âœ… Can re-engineer if feature logic changes
âœ… HIPAA compliance (documented transformation)
```

**Table 13: patient_feature_engineering_log**
```
Tracks how features were engineered:
â”œâ”€ engineering_id (PK)
â”œâ”€ patient_id (FK)
â”œâ”€ feature_engineering_version ('v1.0', 'v2.0')
â”œâ”€ source_type ('X_TEST' vs 'NEW_PATIENT')
â”œâ”€ engineering_timestamp
â””â”€ notes
```

#### New Patient Workflow:

```
STEP 1: User submits form (Frontend)
  Input: age, gender, chronic_conditions[], annual_cost, visits, etc.
  â”‚
  â”œâ”€â†’ Store in new_patient_raw_input table (optional, for audit)
  â”‚
  â””â”€â†’ Move to STEP 2

STEP 2: Feature Engineering (Backend)
  Input: Raw data
  Process: Apply same transformations as X_test
  Output: 27 engineered features
  â”‚
  â”œâ”€â†’ Store intermediate in patient_feature_engineering_log
  â”‚
  â””â”€â†’ Move to STEP 3

STEP 3: Create Patient Record
  INSERT INTO patients (
    external_id, org_id, department_id, data_source='NEW_PATIENT',
    age, gender, race, annual_cost, ...
  )
  
  INSERT INTO patient_features (
    patient_id, is_elderly, has_diabetes, ..., complexity_index
  )
  â”‚
  â””â”€â†’ Move to STEP 4

STEP 4: Run Predictions
  Load 27 features from patient_features
  Run through 3 ML models (30, 60, 90 day)
  Get 3 risk_scores (0.0-1.0)
  Convert to 3 risk_tiers (1-5)
  
  INSERT INTO predictions (3 records)
  â”‚
  â””â”€â†’ Move to STEP 5

STEP 5: Calculate ROI
  For each of 3 predictions:
    window_cost, addressable_cost, intervention_cost,
    expected_savings, net_benefit, roi_percent
  
  INSERT INTO financial_projections (3 records)
  â”‚
  â””â”€â†’ Move to STEP 6

STEP 6: Update Organization Statistics
  REFRESH MATERIALIZED VIEW org_tier_summary
  REFRESH MATERIALIZED VIEW roi_aggregations
  REFRESH MATERIALIZED VIEW dept_risk_distribution
  
  Result: Organization dashboard updated instantly
  â”‚
  â””â”€â†’ COMPLETE: Return predictions to user

Total Time: ~500ms-2s per new patient
```

#### Key Design Insights:

```
âŒ DON'T: Run feature engineering in feature_engineering table
  Reason: Data integrity issues, hard to debug

âœ… DO: Engineer in code â†’ Store result in patient_features
  Reason: Clean separation, easy to audit, can replay if needed

ğŸ“Š New Patient Strategy:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Backend (Python) executes:                               â”‚
â”‚ 1. Parse raw input                                       â”‚
â”‚ 2. Engineer 27 features (using feature_engineering.py)  â”‚
â”‚ 3. Create patient_features record                        â”‚
â”‚ 4. Run predictions (load trained models)                 â”‚
â”‚ 5. Store predictions                                     â”‚
â”‚ 6. Calculate ROI                                         â”‚
â”‚ 7. Refresh materialized views                            â”‚
â”‚ 8. Return JSON response to frontend                      â”‚
â”‚                                                           â”‚
â”‚ Database (PostgreSQL) stores:                            â”‚
â”‚ â†’ patients (1 new record)                                â”‚
â”‚ â†’ patient_features (1 new record)                        â”‚
â”‚ â†’ predictions (3 new records)                            â”‚
â”‚ â†’ financial_projections (3 new records)                  â”‚
â”‚ â†’ new_patient_raw_input (1 new record, optional)         â”‚
â”‚ â†’ Materialized views auto-refresh                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“‹ Complete Table Summary

| # | Table | Purpose | Records | Update Frequency | Notes |
|---|-------|---------|---------|------------------|-------|
| 1 | `organizations` | Organization master | 1 | Never | Static metadata |
| 2 | `departments` | Dept/specialty master | 10 | Rarely | Static reference |
| 3 | `patients` | Patient registry | 3,000+N | Real-time | Grows with new patients |
| 4 | `patient_features` | 27 features per patient | 3,000+N | Real-time | 1:1 with patients |
| 5 | `new_patient_raw_input` | Raw input audit trail | 0+N | Real-time | Optional, for audit |
| 6 | `predictions` | Risk scores per window | 9,000+3N | Batch/Real-time | 3 predictions per patient |
| 7 | `financial_projections` | ROI calculations | 9,000+3N | Batch/Real-time | 3 projections per patient |
| 8 | `org_tier_summary` | **VIEW** Tier distribution | 15 | Auto-refresh | Pre-calculated |
| 9 | `roi_aggregations` | **VIEW** Organization ROI | 3 | Auto-refresh | Pre-calculated |
| 10 | `positive_roi_patients` | **VIEW** Positive ROI list | 1,500-1,800 | Auto-refresh | Filtered view |
| 11 | `dept_risk_distribution` | **VIEW** Dept breakdown | 50 | Auto-refresh | Pre-calculated |
| 12 | `high_risk_by_department` | **VIEW** High-risk only | 20 | Auto-refresh | Filtered view |

**Total Initial Size**: ~150MB for 3,000 patients with 27 features + predictions + ROI

---

## ğŸ¯ Key Design Decisions Summary

### Decision 1: How to Store 27 Features?
**CHOICE: Columns (not JSON)**
- âœ… Can query: `WHERE complexity_index > 0.8`
- âœ… Can index: Index on key features
- âœ… Type-safe: Database enforces types
- âœ… Fast: No JSON parsing overhead

### Decision 2: How to Handle Window-Wise Predictions?
**CHOICE: One record per prediction (9,000 total)**
- âœ… Atomic (can audit any single prediction)
- âœ… Queryable (filter by window, tier, etc.)
- âœ… Aggregatable (SUM/COUNT for summaries)

### Decision 3: How to Handle ROI Calculations?
**CHOICE: Store all calculations explicitly + materialized views for summaries**
- âœ… Atomic (all ROI details in one record)
- âœ… Fast frontend (pre-calculated summaries)
- âœ… Auditable (can trace calculation)

### Decision 4: How to Assign Patients to Departments?
**RECOMMENDATION: Condition-based assignment (Option A)**
- âœ… Clinically meaningful
- âœ… Data-driven (uses actual conditions)
- âœ… Matches hospital reality
- âœ… Enables department-specific interventions

### Decision 5: How to Handle Large Patient IDs?
**CHOICE: Use database BIGINT for external_id**
- âœ… Handles DESYNPUF_ID (up to 2^63-1)
- âœ… Separate from internal patient_id (auto-increment)
- âœ… Both indexed for fast lookup

### Decision 6: How to Track Data Source?
**CHOICE: data_source column (X_TEST vs NEW_PATIENT)**
- âœ… Can compare baseline vs new cohort
- âœ… Can filter by source for analysis
- âœ… Audit trail for compliance

---

## ğŸ”„ Data Flow Diagrams

### Baseline Data Flow (X_test):
```
X_test.csv (3,000 Ã— 27 features)
    â†“
Batch Load Script
    â”œâ”€â†’ Extract patient info (age, gender, race, cost)
    â”œâ”€â†’ INSERT into patients table
    â”œâ”€â†’ INSERT into patient_features table (27 columns)
    â”œâ”€â†’ Assign department by condition (Option A)
    â””â”€â†’ 3,000 patients ready

Then:
    â†“
Load 27 features â†’ Run ML models (3 windows)
    â”œâ”€â†’ INSERT into predictions table (9,000 records)
    â”‚   (Tier distribution: Tier1=1950, Tier2=600, Tier3=300, Tier4=120, Tier5=30 per window)
    â”œâ”€â†’ REFRESH org_tier_summary VIEW
    â””â”€â†’ REFRESH prediction_aggregations VIEW

Then:
    â†“
Calculate ROI for 9,000 predictions
    â”œâ”€â†’ Get intervention_cost by tier
    â”œâ”€â†’ Calculate expected_savings by tierÃ—window
    â”œâ”€â†’ Calculate net_benefit = savings - cost
    â”œâ”€â†’ Calculate roi_percent = (benefit / cost) Ã— 100
    â”œâ”€â†’ INSERT into financial_projections table (9,000 records)
    â”œâ”€â†’ REFRESH roi_aggregations VIEW
    â””â”€â†’ REFRESH positive_roi_patients VIEW

Finally:
    â†“
Organization Dashboard Ready
    â”œâ”€â†’ 3,000 patients in database âœ“
    â”œâ”€â†’ 9,000 predictions window-wise âœ“
    â”œâ”€â†’ 9,000 ROI calculations âœ“
    â”œâ”€â†’ Department distribution available âœ“
    â”œâ”€â†’ High-risk patients identified âœ“
    â””â”€â†’ Organization ROI calculated âœ“
```

### New Patient Flow:
```
New Patient Form (Frontend)
    â†“
Raw Input (age, conditions, cost, visits, etc.)
    â†“ Store (optional: new_patient_raw_input)
    â†“
Feature Engineering (Backend Python)
    â”œâ”€â†’ Apply transformations (same as training data)
    â””â”€â†’ Output: 27 features
         â†“
    INSERT into patients table (1 new record)
    INSERT into patient_features table (1 new record)
    Assign department by condition
         â†“
    Run predictions (3 windows)
         â”œâ”€â†’ INSERT into predictions table (3 records)
         â”œâ”€â†’ REFRESH org_tier_summary (updated)
         â””â”€â†’ REFRESH prediction_aggregations (updated)
         â†“
    Calculate ROI (3 windows)
         â”œâ”€â†’ INSERT into financial_projections table (3 records)
         â”œâ”€â†’ REFRESH roi_aggregations (updated)
         â””â”€â†’ REFRESH positive_roi_patients (updated)
         â†“
    Return Results to User
         â”œâ”€â†’ Risk scores (3 windows)
         â”œâ”€â†’ Risk tiers (3 windows)
         â”œâ”€â†’ ROI percentages (3 windows)
         â””â”€â†’ Department assignment

Organization Dashboard Auto-Updates
    â”œâ”€â†’ Tier distribution updated (+1 patient)
    â”œâ”€â†’ ROI summaries recalculated
    â”œâ”€â†’ Department breakdown updated
    â””â”€â†’ Total patients: now 3,001
```

---

## ğŸ’¾ Storage Size Estimation

```
Base Dataset (3,000 patients):

patients table:
  â”œâ”€ 3,000 rows Ã— 200 bytes = 600 KB
  
patient_features table:
  â”œâ”€ 3,000 rows Ã— 400 bytes (27 columns) = 1.2 MB

predictions table:
  â”œâ”€ 9,000 rows Ã— 150 bytes = 1.3 MB

financial_projections table:
  â”œâ”€ 9,000 rows Ã— 300 bytes = 2.7 MB

Materialized Views (pre-calculated):
  â”œâ”€ org_tier_summary: 15 rows
  â”œâ”€ roi_aggregations: 3 rows
  â”œâ”€ positive_roi_patients: 1,500-1,800 rows Ã— 200 bytes = 300-360 KB
  â”œâ”€ dept_risk_distribution: 50 rows
  â””â”€ high_risk_by_department: 20 rows

TOTAL BASELINE: ~5-6 MB

After 1 Year (assuming 10 new patients/day):
  â”œâ”€ 3,650 patients total
  â”œâ”€ +10,950 predictions (3,650 Ã— 3)
  â”œâ”€ +10,950 financial_projections
  â”œâ”€ +3,650 patient_features
  â””â”€ TOTAL: ~8-10 MB

After 5 Years (assuming 10 new patients/day):
  â”œâ”€ 21,250 patients total
  â”œâ”€ +63,750 predictions
  â”œâ”€ +63,750 financial_projections
  â””â”€ TOTAL: ~40-50 MB

Verdict: âœ… Very small footprint (under 50MB even after 5 years)
         â†’ No storage concerns
         â†’ Can keep all historical data forever
         â†’ Enables trend analysis over time
```

---

## âš¡ Performance Considerations

### Query Performance:

```
Fast Queries (< 100ms):
âœ… "Get tier distribution for 30_day window"
   â†’ SELECT * FROM org_tier_summary WHERE prediction_window='30_day'
   â†’ Pre-calculated, 5 rows

âœ… "Get all high-risk patients"
   â†’ SELECT * FROM high_risk_by_department
   â†’ Pre-calculated, 20 rows

âœ… "Get positive ROI patients"
   â†’ SELECT * FROM positive_roi_patients
   â†’ Pre-calculated, 1,500-1,800 rows

âœ… "Find patients with diabetes in Endocrinology"
   â†’ SELECT p.* FROM patients p
     JOIN patient_features pf ON p.patient_id = pf.patient_id
     WHERE p.department_id = 3 AND pf.has_diabetes = 1
   â†’ Index on (department_id, has_diabetes)
   â†’ Expected: ~300 rows returned, <50ms

Medium Queries (100ms - 1s):
âš ï¸ "Get ROI statistics by department"
   â†’ GROUP BY dept, requires scanning 9,000 predictions
   â†’ Still fast because indexes, but use materialized view

Slow Queries (avoid):
âŒ "Count high-risk patients WITHOUT using views"
   â†’ SELECT COUNT(*) FROM predictions WHERE risk_tier >= 4
   â†’ Scans 9,000 rows every time (no index helps with COUNT)
   â†’ DON'T DO THIS - use pre-calculated view instead
```

### Index Strategy:

```
Essential Indexes:
â”œâ”€ patients(department_id) - Department queries
â”œâ”€ patients(data_source) - X_TEST vs NEW_PATIENT filtering
â”œâ”€ patient_features(patient_id) - Fast feature lookup
â”œâ”€ predictions(patient_id) - Find predictions for patient
â”œâ”€ predictions(prediction_window) - Filter by window
â”œâ”€ predictions(risk_tier) - Filter by risk tier
â”œâ”€ financial_projections(patient_id) - Find ROI for patient
â””â”€ financial_projections(roi_category) - Filter by ROI category

Composite Indexes (speed up joins):
â”œâ”€ (department_id, risk_tier) - Dept + risk queries
â””â”€ (prediction_window, risk_tier) - Window + tier queries

Total: ~10-12 indexes (small overhead, big speed gain)
```

---

## ğŸ¯ Implementation Sequence

### Phase 1: Schema Creation (No code yet, just planning)
```
1. Create 13 base tables (organizations, departments, patients, etc.)
2. Create indexes (10-12 indexes)
3. Create materialized views (6 views)
4. Test connectivity
5. Verify schema with small test data
```

### Phase 2: Baseline Data Loading
```
1. Prepare X_test.csv for import
2. Run batch load script
   â†’ 3,000 patients + 27 features each
   â†’ Automatic department assignment
   â†’ Verify counts match
```

### Phase 3: Prediction & ROI Calculation
```
1. Load trained ML models
2. Run predictions on 3,000 patients (3 windows each)
3. Calculate ROI for 9,000 predictions
4. Store in database
5. Refresh materialized views
```

### Phase 4: New Patient Integration
```
1. Build feature engineering module
2. Integrate with frontend
3. Test end-to-end (raw input â†’ stored in DB)
4. Monitor prediction times
5. Auto-refresh views on each new patient
```

### Phase 5: Dashboard Development
```
1. Query materialized views
2. Build organization-level dashboards
3. Build department-level dashboards
4. Build patient-level details
5. Deploy to frontend
```

---

## ğŸ” Security & Compliance Considerations

```
HIPAA Requirements:
â”œâ”€ Access Control: Only authorized users can query patient data
â”œâ”€ Audit Trail: Log who accessed what data and when
â”œâ”€ Data Retention: Keep records for X years (per your policy)
â”œâ”€ De-identification: Use patient_uuid for reports (not real IDs)
â”œâ”€ Encryption: Encrypt sensitive fields (SSN, MRN, etc.)
â””â”€ Backup: Daily automated backups

Implementation:
â”œâ”€ Use PostgreSQL row-level security (RLS)
â”œâ”€ Implement audit_log table (every access logged)
â”œâ”€ Store external_id separately from internal patient_id
â”œâ”€ Encrypt annual_cost field (financial data)
â”œâ”€ Set up automated backups in Docker volume

Database Role-Based Access:
â”œâ”€ admin_role: Full access (super users only)
â”œâ”€ analyst_role: Can SELECT, not DELETE
â”œâ”€ clinician_role: Can see only their patients
â”œâ”€ system_role: Can INSERT/UPDATE predictions and ROI
```

---

## âœ… Summary: What You Need in Database

### MUST HAVE Tables:
1. **organizations** - Your org metadata
2. **departments** - 10 clinical departments
3. **patients** - 3,000 baseline + new patients
4. **patient_features** - 27 features per patient
5. **predictions** - Risk scores (9,000+ records)
6. **financial_projections** - ROI calculations (9,000+ records)

### SHOULD HAVE Views (Pre-calculated):
7. **org_tier_summary** - Tier distribution by window
8. **roi_aggregations** - Organization-wide ROI stats
9. **positive_roi_patients** - List for intervention targeting
10. **dept_risk_distribution** - High-risk per department
11. **high_risk_by_department** - Only Tier 4+5

### OPTIONAL Audit Tables:
12. **new_patient_raw_input** - Raw input audit trail
13. **audit_log** - Access logging for compliance

### Key Metrics at a Glance:
- Baseline patients: 3,000
- Features per patient: 27
- Prediction windows: 3 (30, 60, 90 day)
- Risk tiers: 5
- Departments: 10
- Total predictions: 9,000+
- Expected database size: <6 MB baseline, ~50 MB after 5 years

---

## ğŸš€ Next Steps (When You're Ready to Code)

1. **Docker PostgreSQL**: Start database container
2. **Schema Creation**: Create 13 tables + indexes + views
3. **Baseline Loading**: Load 3,000 patients from X_test.csv
4. **Prediction Running**: Execute ML models, store predictions
5. **ROI Calculation**: Compute financial projections
6. **Dashboard Building**: Query materialized views
7. **New Patient Integration**: Connect frontend to database

**Current Status**: âœ… Strategy & Design Analysis Complete  
**Waiting For**: Your approval on design before implementation

---

**Questions to Clarify Before Implementation:**

1. âœ… **Department Assignment**: Do you want Condition-Based (Option A) or Risk-Tier (Option B)?
2. â“ **Data Retention**: How long should new patients be retained (6mo, 1yr, forever)?
3. â“ **High-Risk Definition**: Is "High-Risk" = Tier 4+ or only Tier 5?
4. â“ **Audit Trail**: Do you need raw input storage (new_patient_raw_input table)?
5. â“ **Multi-Org**: Future multiple organizations, or single org only?

