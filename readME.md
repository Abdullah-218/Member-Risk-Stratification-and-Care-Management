# ğŸ¥ Healthcare Risk Stratification using Machine Learning

A comprehensive machine learning system to **predict health deterioration risk**, stratify patients into actionable risk tiers, explain AI predictions with SHAP, calculate ROI impact, and optimize models for healthcare organizations.

---

## ğŸ“Œ Overview

Healthcare systems need to identify high-risk patients early to enable proactive interventions, reduce avoidable hospitalizations, and optimize care spending.

This project builds an **end-to-end ML pipeline** that:
- âœ… Curates 15,000 stratified patients from raw CMS data
- âœ… Engineers 27 clinically-relevant features
- âœ… Creates 3 prediction models (30/60/90-day horizons)
- âœ… Trains XGBoost models with strong predictive performance
- âœ… Explains predictions with SHAP explainability
- âœ… Calculates ROI and cost-benefit analysis
- âœ… Optimizes models based on business constraints

---

## ğŸ¯ Problem Statement

> Build an end-to-end ML system that predicts health deterioration risk across multiple time horizons, stratifies patients into actionable tiers, explains predictions with interpretable AI, calculates financial ROI, and optimizes models to balance prediction quality with business constraints.

---

## ğŸ§  Solution Approach

- **Data Processing**: Curate 15K patients from CMS beneficiary and claims data
- **Feature Engineering**: Extract 27 features from demographics, diagnoses, utilization, and costs
- **Target Creation**: Create hierarchical 30/60/90-day deterioration targets
- **Model Training**: Train XGBoost models for each time horizon
- **Explainability**: Use SHAP for global and patient-level interpretability
- **ROI Analysis**: Calculate cost impact and financial ROI
- **Model Optimization**: Fine-tune hyperparameters and select best performers

---

## ğŸ¢ Target Users

- **Healthcare Organizations** â€“ population health management
- **Insurance/Payers** â€“ risk stratification and care targeting
- **Care Management Teams** â€“ intervention prioritization
- **Clinical Leaders** â€“ evidence-based resource allocation

---

## ğŸ“Š Data Sources

- **CMS DE-SynPUF Data** â€“ Synthetic Medicare beneficiary & claims data
  - Beneficiary Summary Files (2008-2009)
  - Inpatient Claims
  - Outpatient Claims
- **Patient Population**: 15,000 stratified Medicare beneficiaries

---

## ğŸ¤– Machine Learning Approach

### Model Selection: XGBoost Classifier
- **Why?** Excellent for tabular healthcare data
- Captures non-linear feature interactions
- Produces well-calibrated probability scores
- Compatible with SHAP explanations
- Handles mixed feature types and missing values

### Multi-Horizon Prediction
- **30-day**: Critical acute events
- **60-day**: Critical + high-risk events  
- **90-day**: All deterioration signals

### Evaluation Metrics
- **Classification**: Precision, Recall, F1-Score
- **Ranking**: ROC-AUC, Average Precision
- **Calibration**: Calibration curves, Hosmer-Lemeshow test

---

## ğŸ“¤ Outputs

### Member-Level
- Risk probability score
- Risk tier (Very Low â†’ Very High)
- Key contributing health factors (SHAP)

### Population-Level
- Risk tier distribution
- High-risk member segmentation

### Evaluation Artifacts
- ROC curves
- Precisionâ€“Recall curves
- Calibration plots
- Feature importance
- SHAP visualizations
- Markdown evaluation report

---

## ğŸ—‚ï¸ Project Structure

```
healthcare-risk-ml/
â”‚
â”œâ”€â”€ ğŸ“ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â””â”€â”€ cms/
â”‚   â”‚       â”œâ”€â”€ beneficiary/           # Beneficiary summary files
â”‚   â”‚       â”œâ”€â”€ inpatient/             # Inpatient claims
â”‚   â”‚       â””â”€â”€ outpatient/            # Outpatient claims
â”‚   â”‚
â”‚   â”œâ”€â”€ processed/
â”‚   â”‚   â”œâ”€â”€ curated_15k_patients.csv   # Final curated dataset (15,000 patients)
â”‚   â”‚   â”œâ”€â”€ curated_patient_ids.csv    # Patient ID mapping
â”‚   â”‚   â”œâ”€â”€ features_27.csv            # 27 engineered features
â”‚   â”‚   â”œâ”€â”€ X_train.csv                # Training features (12,000 samples)
â”‚   â”‚   â”œâ”€â”€ X_test.csv                 # Test features (3,000 samples)
â”‚   â”‚   â”œâ”€â”€ y_30_train.csv             # 30-day target (train)
â”‚   â”‚   â”œâ”€â”€ y_30_test.csv              # 30-day target (test)
â”‚   â”‚   â”œâ”€â”€ y_60_train.csv             # 60-day target (train)
â”‚   â”‚   â”œâ”€â”€ y_60_test.csv              # 60-day target (test)
â”‚   â”‚   â”œâ”€â”€ y_90_train.csv             # 90-day target (train)
â”‚   â”‚   â””â”€â”€ y_90_test.csv              # 90-day target (test)
â”‚   â”‚
â”‚   â””â”€â”€ output/
â”‚       â”œâ”€â”€ comparison/
â”‚       â”‚   â”œâ”€â”€ executive_summary.txt              # Model comparison summary
â”‚       â”‚   â””â”€â”€ model_comparison_results.csv       # Detailed comparison metrics
â”‚       â”‚
â”‚       â”œâ”€â”€ roi/
â”‚       â”‚   â”œâ”€â”€ executive_summary.txt              # ROI analysis summary
â”‚       â”‚   â”œâ”€â”€ patient_level_roi.csv              # Per-patient ROI metrics
â”‚       â”‚   â””â”€â”€ tier_roi_summary.csv               # Tier-level ROI summary
â”‚       â”‚
â”‚       â”œâ”€â”€ roi_optimized/
â”‚       â”‚   â”œâ”€â”€ executive_summary.txt              # Optimized model ROI
â”‚       â”‚   â”œâ”€â”€ patient_level_roi.csv              # Optimized ROI metrics
â”‚       â”‚   â””â”€â”€ tier_summary.csv                   # Optimized tier summary
â”‚       â”‚
â”‚       â”œâ”€â”€ shap/
â”‚       â”‚   â”œâ”€â”€ explainability_report.txt          # SHAP analysis report
â”‚       â”‚   â”œâ”€â”€ tier_analysis.csv                  # Risk tier patterns
â”‚       â”‚   â”œâ”€â”€ global_feature_importance.png      # Global importance plot
â”‚       â”‚   â”œâ”€â”€ summary_30_day.png                 # 30-day SHAP summary
â”‚       â”‚   â”œâ”€â”€ summary_60_day.png                 # 60-day SHAP summary
â”‚       â”‚   â”œâ”€â”€ summary_90_day.png                 # 90-day SHAP summary
â”‚       â”‚   â”œâ”€â”€ dependence_plots.png               # Feature dependence plots
â”‚       â”‚   â”œâ”€â”€ patient_explanation_1.png          # Patient 1 explanation
â”‚       â”‚   â”œâ”€â”€ patient_explanation_2.png          # Patient 2 explanation
â”‚       â”‚   â””â”€â”€ ...                                # Additional patient explanations
â”‚       â”‚
â”‚       â”œâ”€â”€ roc_curves_multiwindow.png             # ROC curves (30/60/90 days)
â”‚       â””â”€â”€ feature_importance.png                 # XGBoost feature importance
â”‚
â”œâ”€â”€ ğŸ“ models/
â”‚   â”œâ”€â”€ xgb_model_30_day.pkl            # 30-day XGBoost model
â”‚   â”œâ”€â”€ xgb_model_60_day.pkl            # 60-day XGBoost model
â”‚   â”œâ”€â”€ xgb_model_90_day.pkl            # 90-day XGBoost model
â”‚   â”œâ”€â”€ feature_names.pkl               # Feature name mapping
â”‚   â”œâ”€â”€ model_performance.pkl           # Performance metrics
â”‚   â”œâ”€â”€ shap_explainer_30_day.pkl       # SHAP explainer (30-day)
â”‚   â”œâ”€â”€ shap_explainer_60_day.pkl       # SHAP explainer (60-day)
â”‚   â””â”€â”€ shap_explainer_90_day.pkl       # SHAP explainer (90-day)
â”‚
â”œâ”€â”€ ğŸ“ src/
â”‚   â”œâ”€â”€ 01_create_curated_dataset.py     # Data loading & curation (15K patients)
â”‚   â”œâ”€â”€ 02_feature_engineering.py        # Feature extraction (27 features)
â”‚   â”œâ”€â”€ 03_create_targets.py             # Target variable creation (30/60/90-day)
â”‚   â”œâ”€â”€ 04_train_models.py               # Model training (3 XGBoost models)
â”‚   â”œâ”€â”€ 05_shap_explainer.py             # SHAP explanations & visualizations
â”‚   â”œâ”€â”€ 06_roi_calculator.py             # ROI & financial impact analysis
â”‚   â”œâ”€â”€ 07_model_comparison_and_optimization.py  # Compare & optimize models
â”‚   â”œâ”€â”€ 08_roi_with_best_models.py       # ROI with optimized models
â”‚   â”œâ”€â”€ 09_final_hyperparameter_tuning.py # Hyperparameter optimization
â”‚   
â”‚
â”œâ”€â”€ ğŸ“ hackathon_dept/                   # Python virtual environment
â”‚   â”œâ”€â”€ bin/                             # Executables (python, pip, etc.)
â”‚   â”œâ”€â”€ lib/                             # Site packages
â”‚   â”œâ”€â”€ include/                         # Headers
â”‚   â””â”€â”€ pyvenv.cfg                       # Environment config
â”‚
â”‚
â”œâ”€â”€ ğŸ“„ run_pipeline.py                   # Main pipeline orchestrator
â”œâ”€â”€ ğŸ“„ requirements.txt                  # Python dependencies
â””â”€â”€ ğŸ“„ README.md                         # This file
```

---

## ğŸ”§ Setup Instructions

### Prerequisites
- Python 3.8+
- macOS/Linux/Windows
- ~2GB disk space for data & models

### Step 1: Create Virtual Environment

```bash
python3 -m venv hackathon_dept
source hackathon_dept/bin/activate  # On Windows: hackathon_dept\Scripts\activate
```

### Step 2: Install Dependencies

```bash
pip install --upgrade pip
pip install -r requirements.txt
```

### Step 3: Verify Installation

```bash
python -c "import xgboost, shap, pandas; print('âœ… All packages installed')"
```

---

## ğŸš€ Execution

### Option 1: Run Full Pipeline (Recommended)

```bash
# From project root directory
python run_pipeline.py
```

This executes all 9 steps sequentially:
1. âœ… Creates 15K curated dataset
2. âœ… Engineers 27 features
3. âœ… Creates 30/60/90-day targets
4. âœ… Trains 3 XGBoost models
5. âœ… Generates SHAP explanations
6. âœ… Calculates ROI metrics
7. âœ… Compares & optimizes models
8. âœ… Calculates optimized ROI
9. âœ… Final hyperparameter tuning

**Output**: `pipeline.log` + all artifacts in `data/output/`

---

### Option 2: Run Step-by-Step

Execute scripts individually in sequence:

```bash
# Step 1: Create curated dataset (15,000 patients)
python src/01_create_curated_dataset.py
# Output: data/processed/curated_15k_patients.csv

# Step 2: Feature engineering (27 features)
python src/02_feature_engineering.py
# Output: data/processed/features_27.csv

# Step 3: Create targets (30/60/90-day)
python src/03_create_targets.py
# Output: data/processed/y_*_train.csv, y_*_test.csv

# Step 4: Train models (XGBoost)
python src/04_train_models.py
# Output: models/xgb_model_*.pkl

# Step 5: SHAP explanations
python src/05_shap_explainer.py
# Output: data/output/shap/*.png, *.csv

# Step 6: ROI analysis
python src/06_roi_calculator.py
# Output: data/output/roi/executive_summary.txt

# Step 7: Model comparison & optimization
python src/07_model_comparison_and_optimization.py
# Output: data/output/comparison/model_comparison_results.csv

# Step 8: ROI with optimized models
python src/08_roi_with_best_models.py
# Output: data/output/roi_optimized/executive_summary.txt

# Step 9: Hyperparameter tuning
python src/09_final_hyperparameter_tuning.py
# Output: Final optimized models
```

---

## ğŸ“Š Expected Results

### Data Pipeline
```
âœ… 15,000 stratified patients
   - Tier 1: 5,250 patients (Low risk)
   - Tier 2: 4,500 patients
   - Tier 3: 3,000 patients
   - Tier 4: 1,500 patients
   - Tier 5: 750 patients (High risk)

âœ… 27 engineered features
   - Demographics: 5 features
   - Chronic conditions: 10 features
   - Utilization: 6 features
   - Costs: 4 features
   - Derived metrics: 2 features
```

### Model Performance
```
30-Day Model:
  ROC-AUC: 0.69 | Avg Precision: 0.23 | Positive Rate: 6.3%

60-Day Model:
  ROC-AUC: 0.70 | Avg Precision: 0.33 | Positive Rate: 14.8%

90-Day Model:
  ROC-AUC: 0.76 | Avg Precision: 0.55 | Positive Rate: 27.3%
```

### Key Risk Drivers
```
Top 10 Features by Importance:
  1. Total annual cost (highest impact)
  2. Cost percentile
  3. Ischemic heart disease
  4. Total inpatient costs
  5. Diabetes diagnosis
  6. High-cost user indicator
  7. Frailty score
  8. Recent admission
  9. Complexity index
  10. ESRD diagnosis
```

### Outputs Generated
```
ğŸ“Š Visualizations:
   âœ… ROC curves (30/60/90-day comparison)
   âœ… Feature importance plots
   âœ… SHAP summary plots (3 models)
   âœ… Patient-level SHAP explanations (5 examples)
   âœ… Dependence plots
   âœ… Risk tier analysis

ğŸ“„ Reports:
   âœ… Model comparison summary
   âœ… SHAP explainability report
   âœ… ROI analysis (original & optimized)
   âœ… Executive summaries

ğŸ“‹ Data Files:
   âœ… Patient-level predictions & ROI
   âœ… Tier-level aggregations
   âœ… Risk tier patterns
```

---

## ğŸ” Model Details

### XGBoost Configuration
```python
max_depth: 6-8
learning_rate: 0.1
n_estimators: 100-200
subsample: 0.8
colsample_bytree: 0.8
scale_pos_weight: Dynamic (based on class imbalance)
```

### Class Imbalance Handling
- Dynamic `scale_pos_weight` based on target distribution
- Stratified train-test splits
- Evaluation via ROC-AUC & Average Precision

### Explainability: SHAP
- **Global**: Feature importance across population
- **Patient-level**: Individual prediction breakdowns
- **Group-level**: Risk tier pattern analysis

---

## ğŸ’° ROI Calculation

### Metrics
- **Sensitivity @ Specificity**: Identify true positives at fixed specificity
- **Cost Avoidance**: Assumed intervention cost vs. prevented event cost
- **Net ROI**: Cost savings minus intervention costs
- **Tier-Level Aggregation**: Total organizational impact

### Assumptions
- Intervention cost: $2,000 per patient
- Prevented event cost: $25,000 per patient
- Risk threshold: Model-specific based on optimization

---

## â­ Key Features

- âœ… **End-to-End Pipeline** â€“ Data ingestion to predictions
- âœ… **Multi-Horizon Prediction** â€“ 30/60/90-day risk forecasting
- âœ… **Explainable AI** â€“ SHAP for interpretability
- âœ… **ROI Analysis** â€“ Financial impact quantification
- âœ… **Model Optimization** â€“ Hyperparameter tuning & comparison
- âœ… **Population Analytics** â€“ Tier-level insights
- âœ… **Production-Ready** â€“ Modular, logged, error-handled
- âœ… **Reproducible** â€“ Fixed seeds & documented steps

---

## ğŸ”® Future Enhancements

### Short-term
- [ ] REST API (FastAPI) for real-time predictions
- [ ] Patient-facing dashboard
- [ ] Retraining pipeline for data drift detection
- [ ] A/B testing framework

### Medium-term
- [ ] Temporal models (LSTM/Transformers)
- [ ] Real-time streaming predictions
- [ ] Integration with EHR systems (FHIR)
- [ ] Cost optimization via reinforcement learning

### Long-term
- [ ] Federated learning across organizations
- [ ] Causal inference for intervention design
- [ ] Patient engagement module
- [ ] Outcome tracking & feedback loops

---

## ğŸ“š References

### Data
- CMS DE-SynPUF: https://www.cms.gov/Research-Statistics-Data-and-Systems/Downloadable-Public-Use-Files/SynPUF/Overview

### Methods
- XGBoost: https://arxiv.org/abs/1603.02754
- SHAP: https://arxiv.org/abs/1705.07874
- Healthcare ML: https://arxiv.org/abs/1901.08387

---

## ğŸ“ Support

For issues or questions:
1. Check `pipeline.log` for error details
2. Verify all input data files exist in `data/raw/`
3. Ensure Python 3.8+ and all dependencies installed
4. Review individual script docstrings for implementation details

---

## ğŸ“ License

This project is provided as-is for educational and research purposes.

---

**Last Updated**: January 2026  
**Status**: âœ… Production Ready